{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据集\n",
    "np.random.seed(0)\n",
    "X, y = sklearn.datasets.make_moons(200, noise = 0.2)\n",
    "# X的每一行表示特征个数，即神经元个数，200行表示有200个样本\n",
    "# y表示每个样本的真实值，只有0和1，可以理解为真与否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74346118  0.46465633]\n",
      " [ 1.65755662 -0.63203157]\n",
      " [-0.15878875  0.25584465]\n",
      " [-1.088752   -0.39694315]\n",
      " [ 1.768052   -0.25443213]\n",
      " [ 1.95416454 -0.12850579]\n",
      " [ 0.93694537  0.36597075]\n",
      " [ 0.88446589 -0.47595401]\n",
      " [ 0.80950246  0.3505231 ]\n",
      " [ 1.2278091  -0.64785108]\n",
      " [-0.38454276  0.50916381]\n",
      " [ 0.09252135 -0.31618454]\n",
      " [ 1.79531658 -0.32235591]\n",
      " [ 1.43861749 -0.15796611]\n",
      " [-0.82364866  0.86822754]\n",
      " [ 0.99633397  0.1731019 ]\n",
      " [ 0.66388701  0.94659669]\n",
      " [ 0.13229471 -0.26032619]\n",
      " [ 0.2482245   0.7860477 ]\n",
      " [-1.00392102  1.15207238]\n",
      " [ 2.08208438  0.00715606]\n",
      " [ 0.87081342 -0.4366643 ]\n",
      " [ 0.37268327  1.01743002]\n",
      " [ 1.26735927 -0.11813675]\n",
      " [-0.13270154  1.26653562]\n",
      " [ 0.20331     0.19519454]\n",
      " [ 1.98373996 -0.11222315]\n",
      " [ 1.82749513 -0.03085446]\n",
      " [-0.03857867  0.0838378 ]\n",
      " [ 0.03351023  0.63113817]\n",
      " [ 0.94193283  0.63204507]\n",
      " [-0.39131894  0.40925201]\n",
      " [ 0.88357043 -0.35868845]\n",
      " [-0.01141219  0.30437635]\n",
      " [ 0.75877114  0.76057045]\n",
      " [ 1.79414416  0.28323389]\n",
      " [ 0.56116634 -0.0330033 ]\n",
      " [ 0.87161309  0.01715969]\n",
      " [-0.75191922  0.63798317]\n",
      " [-0.21911253  0.49662864]\n",
      " [ 0.63711933 -0.55537183]\n",
      " [-0.25531442  0.83953933]\n",
      " [ 0.57753017  0.64564015]\n",
      " [ 0.15931878 -0.02835184]\n",
      " [ 1.53296943 -0.36277826]\n",
      " [-0.24648981  1.09136047]\n",
      " [ 1.16443301  0.01495781]\n",
      " [-0.70574528  0.54883003]\n",
      " [ 0.16919147 -0.30895665]\n",
      " [ 1.0717818  -0.40141988]\n",
      " [-0.8970433   0.87690996]\n",
      " [ 0.4828491  -0.21452374]\n",
      " [ 2.25536302  0.02862685]\n",
      " [-0.62523133  0.03868576]\n",
      " [ 1.22821377 -0.50119159]\n",
      " [ 0.84248307  0.55728315]\n",
      " [ 0.45857236  0.5017019 ]\n",
      " [ 0.98031957 -0.56811367]\n",
      " [ 0.1059936   0.90514125]\n",
      " [-0.21582418  1.03521642]\n",
      " [ 0.06721632 -0.1649077 ]\n",
      " [-1.07873435  0.36644163]\n",
      " [ 1.60172165 -0.37604995]\n",
      " [ 1.02592325  0.42143427]\n",
      " [ 1.06739115 -0.38783511]\n",
      " [-1.35462041  0.28524762]\n",
      " [-0.20784982  1.09043495]\n",
      " [ 1.61652485 -0.29469483]\n",
      " [ 0.26375409  0.91508367]\n",
      " [-0.99805184  0.62420544]\n",
      " [ 0.62273618 -0.52804644]\n",
      " [-1.0873102   0.78128608]\n",
      " [ 0.01262924 -0.59715374]\n",
      " [-0.52953439  0.69307316]\n",
      " [ 0.78362442 -0.25844144]\n",
      " [-0.94262451  0.57258351]\n",
      " [ 0.09048712  0.0890939 ]\n",
      " [ 0.99716574  0.35017425]\n",
      " [ 0.4630177   0.86392418]\n",
      " [ 0.71787709 -0.09708361]\n",
      " [ 2.13330659  0.11200406]\n",
      " [-0.41467068  0.92254691]\n",
      " [ 0.6233932  -0.69422694]\n",
      " [ 2.04970274  0.66368306]\n",
      " [-0.00353234  0.21487064]\n",
      " [-0.27631969  1.34161045]\n",
      " [ 0.82262609 -0.02317445]\n",
      " [-0.46610015  0.98764879]\n",
      " [ 0.64426474 -0.36209808]\n",
      " [ 1.96682571  0.2646737 ]\n",
      " [ 0.71060915  0.80990546]\n",
      " [ 1.12820353  0.4664342 ]\n",
      " [ 1.99150162  0.02534858]\n",
      " [-0.66342048  0.85301441]\n",
      " [ 2.0436285   0.24563453]\n",
      " [ 1.77377397 -0.10513907]\n",
      " [ 1.773464   -0.34102513]\n",
      " [ 0.66137686 -0.31314104]\n",
      " [-1.15442774  0.40574243]\n",
      " [ 0.04167562 -0.07462092]\n",
      " [ 1.40426435 -0.93206382]\n",
      " [ 1.99317676  0.48903983]\n",
      " [ 0.17673342  1.3178874 ]\n",
      " [ 1.12344625 -0.09556327]\n",
      " [-0.64018301  0.75214137]\n",
      " [ 0.17295579  0.60135526]\n",
      " [-0.97644617  0.03612864]\n",
      " [-0.56357758  1.15774717]\n",
      " [ 1.60440089 -0.35116358]\n",
      " [ 0.13387667  0.6944329 ]\n",
      " [-0.59909677  0.76903039]\n",
      " [ 0.1023533   1.09326207]\n",
      " [-0.22047436  1.28343927]\n",
      " [-0.70416708  0.30649274]\n",
      " [ 0.95709601  0.30502143]\n",
      " [ 1.65936346 -0.70351567]\n",
      " [ 0.18911691  0.64887424]\n",
      " [ 2.02773677  0.25021451]\n",
      " [ 0.6515764  -0.40677494]\n",
      " [ 0.55688998  0.26120887]\n",
      " [ 0.81816111  0.78952806]\n",
      " [-0.48367053  0.43679813]\n",
      " [-0.14739828  0.22556193]\n",
      " [ 0.11834786  0.99156023]\n",
      " [-0.25253387  0.18776697]\n",
      " [-0.93313522  0.73385959]\n",
      " [ 0.6975216  -0.11832611]\n",
      " [ 0.33332321  0.14006592]\n",
      " [ 1.06519327 -0.38867949]\n",
      " [ 1.9369961   0.63112161]\n",
      " [ 1.05840957  0.51858443]\n",
      " [-0.50840939  0.55259494]\n",
      " [-1.32109805  0.51437657]\n",
      " [ 0.29449971 -0.26078938]\n",
      " [ 1.33653621 -0.18005761]\n",
      " [ 1.51241178  0.11081331]\n",
      " [ 1.01934807 -0.17993629]\n",
      " [-1.13305483  0.11109962]\n",
      " [ 2.07463826  0.51253705]\n",
      " [ 0.73451679  0.5346233 ]\n",
      " [-0.12213442  0.15292037]\n",
      " [-0.0557186   0.57286794]\n",
      " [ 0.45046033  1.09585861]\n",
      " [-0.7204608   1.01733354]\n",
      " [-0.33698825  0.89060661]\n",
      " [ 1.0628775   0.17231496]\n",
      " [ 0.34005355  0.32486358]\n",
      " [ 1.24491552 -0.5137574 ]\n",
      " [ 0.30966003  1.16677531]\n",
      " [-0.06114159 -0.02921072]\n",
      " [ 0.48281721 -0.43196099]\n",
      " [ 1.68734249 -0.6872367 ]\n",
      " [ 0.80862106  0.28415372]\n",
      " [ 0.29809162  0.82211432]\n",
      " [ 0.8496547  -0.30507345]\n",
      " [-0.3802171   0.88414623]\n",
      " [ 1.32734432 -0.48056888]\n",
      " [ 0.23337057  0.10750568]\n",
      " [ 0.68841773  1.15068264]\n",
      " [ 0.6779624   0.78024482]\n",
      " [ 0.3395913  -0.02223857]\n",
      " [ 1.30440877 -0.52950917]\n",
      " [ 0.75307594  0.8526869 ]\n",
      " [ 1.4298847  -0.21080222]\n",
      " [ 0.55631903 -0.70781481]\n",
      " [ 1.45384401  0.12718529]\n",
      " [ 0.3203754   0.87271389]\n",
      " [ 0.53148147 -0.27424077]\n",
      " [ 1.51658699 -0.45069719]\n",
      " [ 0.99826403 -0.80979075]\n",
      " [ 0.63918299  0.96606739]\n",
      " [-1.2855903   0.10677262]\n",
      " [-1.07840959  0.56402523]\n",
      " [-0.57716798  0.2942259 ]\n",
      " [ 0.25403599 -0.00644002]\n",
      " [ 0.91722632 -0.29657499]\n",
      " [ 1.43380709  0.69183071]\n",
      " [-0.70851168  0.49617855]\n",
      " [-0.64683386  0.46971252]\n",
      " [ 0.30143461  0.76398572]\n",
      " [ 1.48069489 -0.3572808 ]\n",
      " [-1.02663961  0.41265823]\n",
      " [ 1.89660871  0.25413209]\n",
      " [ 2.04251223 -0.46074593]\n",
      " [ 1.92673019  0.40817963]\n",
      " [ 0.35766276  1.0872811 ]\n",
      " [ 0.1240315   0.67672995]\n",
      " [ 0.97332087 -0.70530678]\n",
      " [-0.72894228  0.44179419]\n",
      " [-0.69863061  0.77620293]\n",
      " [-0.93516752  0.43520803]\n",
      " [ 0.45166927  1.00185497]\n",
      " [ 0.87629641  0.28951999]\n",
      " [ 0.88155818  0.23925957]\n",
      " [-0.07795147  0.27995261]\n",
      " [-0.56365899  0.8918972 ]\n",
      " [ 1.6049806   0.13835516]\n",
      " [ 0.27695668  0.01210816]\n",
      " [ 0.25919429  1.04104213]\n",
      " [ 1.5215205  -0.1258923 ]]\n",
      "[0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
      " 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = len(X)   # size of training set\n",
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_input_dim = 2   # 表示神经元个数，即输入的参数的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    z1 = X.dot(W1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    exp_scores = np.exp(z2)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis = 1, keepdims = True)\n",
    "    \n",
    "    log_probs = -np.log(probs[range(num_examples), y])\n",
    "    loss = np.sum(log_probs)\n",
    "    \n",
    "    return 1./num_examples * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(nn_hdim, num_passes = 30000, print_loss = False):\n",
    "    # nn_hdim 表示隐藏层的个数\n",
    "    # nn_imput_dim表示神经元个数，即输入层个数\n",
    "    # / np.sqrt(nn_input_dim) 进行了标准化\n",
    "    # W1表示输入层到隐藏层的权值矩阵\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    # nn_output_dim 表示输出层的个数\n",
    "    # W2 表示隐藏层到输出层的权值矩阵\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
    "    b2 = np.zeros((1, nn_output_dim))\n",
    "    \n",
    "    model = {}\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(0, num_passes):\n",
    "        # forward\n",
    "        z1 = X.dot(W1) + b1   # 得到隐藏层的输入z1，固定行的某个元素表示固定样本的隐藏层的某个输入\n",
    "        a1 = np.tanh(z1)      # activate func tanh， 得到隐藏层的输出\n",
    "        z2 = a1.dot(W2) + b2  # 此时，把隐藏层的输出变成输出层的输入，得到输出层的输入\n",
    "        exp_scores = np.exp(z2)   # 作用exp()\n",
    "        probs = exp_scores / np.sum(exp_scores, axis = 1, keepdims = True)  # this is softmax\n",
    "        # softmax，得到probs是最终的结果\n",
    "        \n",
    "        # bp\n",
    "        delta3 = probs\n",
    "        delta3[range(num_examples), y] -= 1\n",
    "        # 对softmax求导，意思大概是取X每一行列坐标为y对应的值，\n",
    "        # 比如第i行的列坐标取y的第i个元素的值\n",
    "        # this is the derivative of softmax[no need to thoroughly understand yet]\n",
    "        # we'll revisit in week later\n",
    "        \n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis = 0, keepdims = True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2)) # tanh derivative\n",
    "        dW1 = np.dot(X.T, delta2)\n",
    "        db1 = np.sum(delta2, axis = 0)\n",
    "        \n",
    "        # optional\n",
    "        W1 += -lr * dW1\n",
    "        b1 += -lr * db1\n",
    "        W2 += -lr * dW2\n",
    "        b2 += -lr * db2\n",
    "        \n",
    "        model = {'W1':W1, 'b1':b1, 'W2':W2, 'b2':b2}\n",
    "        \n",
    "        if print_loss and i % 1000 ==  0:\n",
    "            print(\"Loss after iteration %i: %f\" % (i, calculate_loss(model)))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.362723\n",
      "Loss after iteration 1000: 0.072866\n",
      "Loss after iteration 2000: 0.053184\n",
      "Loss after iteration 3000: 0.041005\n",
      "Loss after iteration 4000: 0.029380\n",
      "Loss after iteration 5000: 0.023095\n",
      "Loss after iteration 6000: 0.018241\n",
      "Loss after iteration 7000: 0.015106\n",
      "Loss after iteration 8000: 0.013222\n",
      "Loss after iteration 9000: 0.012009\n",
      "Loss after iteration 10000: 0.011162\n",
      "Loss after iteration 11000: 0.010518\n",
      "Loss after iteration 12000: 0.009996\n",
      "Loss after iteration 13000: 0.009550\n",
      "Loss after iteration 14000: 0.009156\n",
      "Loss after iteration 15000: 0.008800\n",
      "Loss after iteration 16000: 0.008466\n",
      "Loss after iteration 17000: 0.008137\n",
      "Loss after iteration 18000: 0.007796\n",
      "Loss after iteration 19000: 0.007427\n",
      "Loss after iteration 20000: 0.007017\n",
      "Loss after iteration 21000: 0.006557\n",
      "Loss after iteration 22000: 0.006059\n",
      "Loss after iteration 23000: 0.005545\n",
      "Loss after iteration 24000: 0.005027\n",
      "Loss after iteration 25000: 0.004517\n",
      "Loss after iteration 26000: 0.004028\n",
      "Loss after iteration 27000: 0.003575\n",
      "Loss after iteration 28000: 0.003165\n",
      "Loss after iteration 29000: 0.002802\n"
     ]
    }
   ],
   "source": [
    "# n-dimensional hidden layer\n",
    "model = build_model(10, print_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
